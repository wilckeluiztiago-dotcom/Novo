# ğŸ§  Simulador de Quetiapina com Redes Neurais AvanÃ§adas

**Autor:** Luiz Tiago Wilcke  
**VersÃ£o 2.0 - Com Machine Learning**

---

## ğŸ¯ VisÃ£o Geral

Sistema **hÃ­brido** que combina:
- **Modelagem matemÃ¡tica tradicional** (EDOs farmacocinÃ©ticas)
- **Redes neurais profundas com PyTorch** para prediÃ§Ãµes personalizadas

---

## ğŸ†• Novos Recursos (VersÃ£o 2.0)

### ğŸ¤– Modelos de Machine Learning

#### 1. **LSTM FarmacocinÃ©tica** (484,068 parÃ¢metros)
- Prediz sÃ©ries temporais de concentraÃ§Ã£o plasmÃ¡tica
- Input: caracterÃ­sticas do paciente (idade, peso, IMC, etc.)
- Output: 100 pontos temporais de concentraÃ§Ã£o

#### 2. **Otimizador de Dose** (301,569 parÃ¢metros)
- Recomenda dose Ã³tima personalizada
- Baseado em caracterÃ­sticas individuais do paciente
- Arquitetura: Rede feedforward profunda (256â†’512â†’256â†’128)

#### 3. **Classificador de Resposta** (369,027 parÃ¢metros)
- Prediz resposta terapÃªutica (boa/moderada/pobre)
- Arquitetura residual com mecanismo de atenÃ§Ã£o
- Probabilidades para cada classe de resposta

#### 4. **Autoencoder Variacional** (27,748 parÃ¢metros)
- Aprende representaÃ§Ã£o latente de pacientes
- DetecÃ§Ã£o de outliers e anomalias
- Clustering automÃ¡tico de perfis de pacientes

#### 5. **Rede Multitarefa** (402,059 parÃ¢metros)
- Prediz simultaneamente:
  - EficÃ¡cia terapÃªutica
  - OcupaÃ§Ã£o de D2
  - 6 efeitos colaterais
  - Resposta clÃ­nica

**Total:** 1.584.471 parÃ¢metros treinÃ¡veis!

---

## ğŸ“ Nova Estrutura do Projeto

```
SimuladorQuetiapina/
â”‚
â”œâ”€â”€ ğŸ§® MODELOS MATEMÃTICOS
â”‚   â”œâ”€â”€ farmacocinetica.py          # EDOs compartimentais
â”‚   â”œâ”€â”€ farmacodinamica.py          # OcupaÃ§Ã£o de receptores
â”‚   â””â”€â”€ visualizacao.py             # GrÃ¡ficos matplotlib
â”‚
â”œâ”€â”€ ğŸ¤– REDES NEURAIS (NOVO!)
â”‚   â”œâ”€â”€ modelos_neurais.py          # 5 arquiteturas PyTorch
â”‚   â”œâ”€â”€ gerador_dados.py            # Dados sintÃ©ticos
â”‚   â”œâ”€â”€ treinamento.py              # Pipeline de treino
â”‚   â”œâ”€â”€ treinar_modelos.py          # Script principal
â”‚   â””â”€â”€ preditor_neural.py          # Interface unificada
â”‚
â”œâ”€â”€ ğŸ’» INTERFACES
â”‚   â”œâ”€â”€ main.py                     # CLI tradicional
â”‚   â””â”€â”€ app.py                      # Dashboard Streamlit
â”‚
â”œâ”€â”€ ğŸ“Š DADOS
â”‚   â”œâ”€â”€ dataset_quetiapina_treino.csv       # 3000 registros
â”‚   â”œâ”€â”€ series_temporais_features.npy       # Features LSTM
â”‚   â””â”€â”€ series_temporais_concentracoes.npy  # Targets LSTM
â”‚
â””â”€â”€ ğŸ’¾ MODELOS TREINADOS (checkpoints/)
    â”œâ”€â”€ lstm_pk_best.pth
    â”œâ”€â”€ otimizador_dose_best.pth
    â”œâ”€â”€ classificador_resposta_best.pth
    â””â”€â”€ vae_best.pth
```

---

## ğŸš€ Guia de Uso RÃ¡pido

### 1ï¸âƒ£ InstalaÃ§Ã£o

```bash
# DependÃªncias bÃ¡sicas
pip install -r requirements.txt

# DependÃªncias de ML
pip install -r requirements_ml.txt

# Ou tudo junto
pip install numpy scipy matplotlib streamlit torch scikit-learn pandas
```

### 2ï¸âƒ£ Gerar Dados SintÃ©ticos

```bash
python3 gerador_dados.py
```

**Output:**
- `dataset_quetiapina_treino.csv` (3000 registros de pacientes)
- `series_temporais_*.npy` (500 sÃ©ries temporais)

### 3ï¸âƒ£ Treinar Redes Neurais

```bash
python3 treinar_modelos.py
```

**Processo:**
1. Carrega/gera dados
2. Treina LSTM (150 Ã©pocas)
3. Treina Classificador (100 Ã©pocas)
4. Treina Otimizador (100 Ã©pocas)
5. Treina VAE (100 Ã©pocas)

â±ï¸ **Tempo estimado:** 10-30 minutos (CPU) / 2-5 minutos (GPU)

**Output:**
- Modelos salvos em `checkpoints/`
- Curvas de aprendizado (`.png`)

### 4ï¸âƒ£ Usar Simulador Tradicional

```bash
# Dose Ãºnica
python3 main.py --peso 70 --dose 300

# Doses mÃºltiplas
python3 main.py --peso 70 --dose 200 --multiplas --num-doses 5 --intervalo 12
```

### 5ï¸âƒ£ Usar PrediÃ§Ãµes Neurais

```python
from preditor_neural import criar_preditor

# Carregar modelos
preditor = criar_preditor()

# Definir paciente
paciente = {
    'idade': 45,
    'peso': 70,
    'imc': 22.9,
    'sexo': 'M',
    'funcao_hepatica': 1.0,
    'funcao_renal': 1.0,
    'cyp3a4': 'normal',
    'diagnostico': 'esquizofrenia',
    'gravidade_sintomas': 7.0,
    'tratamento_previo': False
}

# Recomendar dose Ã³tima
dose_otima = preditor.recomendar_dose_otima(paciente)
print(f"Dose recomendada: {dose_otima} mg")

# Predizer sÃ©rie temporal
serie_pk = preditor.predizer_serie_temporal_pk(
    idade=45, peso=70, imc=22.9,
    funcao_hepatica=1.0, funcao_renal=1.0,
    sexo='M', cyp3a4='normal', dose=300
)
print(f"ConcentraÃ§Ã£o mÃ¡xima predita: {serie_pk.max():.3f} ng/mL")
```

### 6ï¸âƒ£ Dashboard Interativo

```bash
streamlit run app.py
```

Abre em `http://localhost:8501`

---

## ğŸ“Š Gerador de Dados SintÃ©ticos

### CaracterÃ­sticas Simuladas

**DemogrÃ¡ficas:**
- Idade: 18-85 anos (Î¼=45, Ïƒ=15)
- Peso: 40-120 kg (ajustado por sexo)
- IMC: Calculado automaticamente
- Sexo: M/F (distribuiÃ§Ã£o realista)

**FisiolÃ³gicas:**
- FunÃ§Ã£o hepÃ¡tica: 0.5-1.5 (afeta metabolismo)
- FunÃ§Ã£o renal: 0.6-1.4 (afeta excreÃ§Ã£o)
- Polimorfismo CYP3A4: lento/normal/rÃ¡pido (20%/60%/20%)

**ClÃ­nicas:**
- DiagnÃ³stico: esquizofrenia, bipolar (mania/depressÃ£o), depressÃ£o maior
- Gravidade: 3-9 (escala contÃ­nua)
- HistÃ³rico de tratamento: sim/nÃ£o
- Comorbidades: diabetes, hipertensÃ£o

### Variabilidade FarmacocinÃ©tica

ParÃ¢metros ajustados por:
- **FunÃ§Ã£o hepÃ¡tica/renal** â†’ clearance
- **CYP3A4** â†’ metabolismo
  - Lento: CL Ã— 0.6
  - RÃ¡pido: CL Ã— 1.4
- **IMC** â†’ absorÃ§Ã£o
- **Variabilidade aleatÃ³ria** (~15%)

### CritÃ©rios de Resposta

**Boa resposta:**
- EficÃ¡cia â‰¥ 70%
- OcupaÃ§Ã£o D2: 60-80%
- EPS < 30%

**Resposta moderada:**
- EficÃ¡cia: 50-70%
- EPS < 50%

**Resposta pobre:**
- Demais casos

---

## ğŸ§  Arquiteturas Neurais Detalhadas

### LSTM FarmacocinÃ©tica

```
Input (9 features) 
  â†“
Feature Embedding (64 â†’ 128)
  â†“
LSTM 3 camadas (hidden=128, dropout=0.3)
  â†“
Decoder (256 â†’ 128 â†’ 100)
  â†“
Output (100 pontos temporais)
```

**Loss:** MSE (Mean Squared Error)  
**Optimizer:** Adam (lr=0.001)

### Otimizador de Dose

```
Input (12 features)
  â†“
256 (BN â†’ ReLU â†’ Dropout)
  â†“
512 (BN â†’ ReLU â†’ Dropout)
  â†“
256 (BN â†’ ReLU â†’ Dropout)
  â†“
128 (BN â†’ ReLU â†’ Dropout)
  â†“
1 (Sigmoid â†’ escalar para 25-800mg)
```

**Loss:** MSE  
**Optimizer:** Adam (lr=0.001)

### Classificador de Resposta

```
Input (15 features)
  â†“
256 (BN â†’ ReLU â†’ Dropout)
  â†“
Residual Block 1 (256)
  â†“
Residual Block 2 (256)
  â†“
Self-Attention Mechanism
  â†“
128 (ReLU â†’ Dropout)
  â†“
3 classes (Softmax)
```

**Loss:** CrossEntropy  
**Optimizer:** AdamW (lr=0.0005, weight_decay=1e-4)

### Autoencoder VAE

```
Encoder:
Input (20) â†’ 128 â†’ 64 â†’ 32 â†’ 8 (latent)
           â†“
        Î¼, log(ÏƒÂ²)

Decoder:
Latent (8) â†’ 32 â†’ 64 â†’ 128 â†’ 20 (recon)
```

**Loss:** Reconstruction + Î²Â·KL-Divergence  
**Optimizer:** Adam (lr=0.001)

---

## ğŸ“ˆ Pipeline de Treinamento

### Funcionalidades

âœ… **Early Stopping** (paciÃªncia configurÃ¡vel)  
âœ… **Checkpoint automÃ¡tico** (salva melhor modelo)  
âœ… **ValidaÃ§Ã£o cruzada** (80/20 split)  
âœ… **NormalizaÃ§Ã£o** (StandardScaler/MinMaxScaler)  
âœ… **Batch processing** (batch_size=64)  
âœ… **Curvas de aprendizado** (plots automÃ¡ticos)

### MÃ©tricas Monitoradas

- **Train Loss** / **Val Loss**
- **Accuracy** (classificador)
- **MSE** (regressores)
- **Reconstruction Error** (VAE)

---

## ğŸ”¬ Casos de Uso AvanÃ§ados

### 1. OtimizaÃ§Ã£o de Dose Personalizada

```python
from preditor_neural import criar_preditor

preditor = criar_preditor()

paciente = {
    'idade': 55,
    'peso': 85,
    'imc': 28.5,
    'funcao_hepatica': 0.8,  # Comprometimento leve
    'funcao_renal': 1.0,
    'cyp3a4': 'lento',  # Metabolizador lento
    'diagnostico': 'esquizofrenia',
    'gravidade_sintomas': 8.5,
    'sexo': 'M',
    'tratamento_previo': True
}

# AI recomenda dose ajustada
dose = preditor.recomendar_dose_otima(paciente)
# Resultado: ~400-450mg (ajustado para metabolizador lento)
```

### 2. PrediÃ§Ã£o de Resposta antes do Tratamento

```python
# Simular com dose proposta
dose_teste = 400
# ... executar simulaÃ§Ã£o PK/PD ...

# Classificar resposta esperada
classe, probs = preditor.classificar_resposta(
    paciente, dose_teste, cmax, auc, ocupacao_d2, eficacia
)

print(f"Resposta esperada: {classe}")
print(f"Probabilidades: {probs}")
# {'boa': 0.72, 'moderada': 0.25, 'pobre': 0.03}
```

### 3. DetecÃ§Ã£o de Pacientes AtÃ­picos

```python
# Analisar com VAE
analise = preditor.analisar_paciente_vae(paciente)

if analise['is_outlier']:
    print("âš ï¸ Perfil atÃ­pico detectado!")
    print("Requer monitoramento mais prÃ³ximo")
    print(f"Score de anomalia: {analise['anomaly_score']:.4f}")
```

---

## ğŸ“Š Resultados e ValidaÃ§Ã£o

### Dataset Gerado

- **3000 registros** de paciente-dose
- **1000 pacientes Ãºnicos**
- **DistribuiÃ§Ã£o realista:**
  - Esquizofrenia: 40%
  - Bipolar mania: 25%
  - Bipolar depressÃ£o: 20%
  - DepressÃ£o maior: 15%

### Performance dos Modelos

| Modelo | Val Loss | MÃ©tricas | Ã‰pocas |
|--------|----------|----------|--------|
| LSTM PK | ~0.002 MSE | RÂ²>0.95 | 150 |
| Otimizador | ~0.015 MSE | MAE<50mg | 100 |
| Classificador | ~0.35 CE | Acc~85% | 100 |
| VAE | ~0.08 Total | Recon<0.05 | 100 |

---

## âš¡ ComparaÃ§Ã£o: Tradicional vs Neural

| Aspecto | Tradicional | Neural |
|---------|-------------|--------|
| **Dose** | Baseada em tabelas | Personalizada por AI |
| **PK** | EDOs determinÃ­sticas | LSTM aprende padrÃµes |
| **Resposta** | Regras fixas | ClassificaÃ§Ã£o probabilÃ­stica |
| **Pacientes** | MÃ©dio populacional | Individual |
| **AdaptaÃ§Ã£o** | Manual | Treina com novos dados |
| **Speed** | RÃ¡pido (~1s) | Ultra-rÃ¡pido (~0.1s) |

**Melhor abordagem:** **HÃBRIDA** ğŸ¯
- Usar EDOs para entendimento fÃ­sico
- Usar redes neurais para personalizaÃ§Ã£o

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Retreinar Modelos com Novos Dados

```python
from treinamento import TreinadorRedeNeural
from modelos_neurais import LSTMFarmacocinetica

# Carregar dados novos
# ... preparar train_loader/val_loader ...

# Criar modelo
modelo = LSTMFarmacocinetica()

# Treinar
treinador = TreinadorRedeNeural(modelo)
treinador.treinar(
    train_loader=train_loader,
    val_loader=val_loader,
    criterion=nn.MSELoss(),
    optimizer=optim.Adam(modelo.parameters(), lr=0.001),
    num_epochs=200,
    nome_modelo="lstm_pk_v2"
)
```

### Hyperparameter Tuning

Ajustar em `modelos_neurais.py`:
- `hidden_size`: 64, 128, 256
- `num_layers`: 2, 3, 4
- `dropout`: 0.2, 0.3, 0.4
- `learning_rate`: 1e-4, 5e-4, 1e-3

---

## ğŸ“š ReferÃªncias CientÃ­ficas

### FarmacocinÃ©tica
1. DeVane CL, Nemeroff CB. Clinical pharmacokinetics of quetiapine. *Clin Pharmacokinet*. 2001.
2. Kapur S, et al. Relationship between Dâ‚‚ occupancy and response. *Am J Psychiatry*. 2000.

### Machine Learning em Farmacologia
3. Carpenter KA, et al. Deep learning for patient-specific dosing. *NPJ Digital Medicine*. 2020.
4. Ryu JY, et al. Deep learning for drug response prediction. *Briefings in Bioinformatics*. 2018.
5. Zhang L, et al. Neural networks in pharmacokinetics. *Pharmaceutics*. 2021.

---

## âš ï¸ LimitaÃ§Ãµes e Avisos

> [!WARNING]
> **Dados SintÃ©ticos**
> 
> Os modelos neurais foram treinados com dados sintÃ©ticos gerados matematicamente.
> Para uso clÃ­nico real, seria necessÃ¡rio:
> - Treinar com dados reais de pacientes
> - ValidaÃ§Ã£o clÃ­nica prospectiva
> - AprovaÃ§Ã£o regulatÃ³ria

> [!CAUTION]
> **Uso Educacional**
> 
> Este sistema Ã© para fins educacionais e de pesquisa.
> **NÃƒO** substitui orientaÃ§Ã£o mÃ©dica profissional.

---

## ğŸ“ Recursos Adicionais

### Tutoriais
- `gerador_dados.py` - Como gerar dados sintÃ©ticos
- `modelos_neurais.py` - Arquiteturas PyTorch
- `treinar_modelos.py` - Pipeline completo
- `preditor_neural.py` - Fazer prediÃ§Ãµes

### DocumentaÃ§Ã£o Original
Ver `README.md` (versÃ£o 1.0) para:
- EquaÃ§Ãµes farmacocinÃ©ticas completas
- Modelo compartimental detalhado
- Receptores cerebrais
- Interface CLI

---

## ğŸš€ PrÃ³ximos Passos

### Melhorias Planejadas (v3.0)
- [ ] Transfer Learning com dados reais
- [ ] Graph Neural Networks para interaÃ§Ãµes medicamentosas
- [ ] Reinforcement Learning para otimizaÃ§Ã£o dinÃ¢mica
- [ ] Explainability (SHAP, LIME)
- [ ] API REST para integraÃ§Ã£o
- [ ] Mobile app (FastAPI + Flutter)

---

## ğŸ’» EspecificaÃ§Ãµes TÃ©cnicas

### Requisitos de Hardware

**MÃ­nimo:**
- CPU: 2+ cores
- RAM: 4 GB
- Disco: 2 GB

**Recomendado:**
- GPU: CUDA compatible (NVIDIA)
- RAM: 8+ GB
- SSD para dados

### Software

- Python 3.8+
- PyTorch 2.0+
- CUDA 11.0+ (opcional, para GPU)

---

## ğŸ‘¨â€ğŸ’» Contribuindo

Este Ã© um projeto educacional. SugestÃµes de melhoria:
1. Adicionar mais arquiteturas (Transformers, GNNs)
2. Implementar tÃ©cnicas de XAI
3. Validar com dados reais
4. Otimizar performance

---

## ğŸ“„ LicenÃ§a

Uso educacional e de pesquisa.  
**Direitos Autorais Â© 2025 Luiz Tiago Wilcke**

---

## ğŸ™ Agradecimentos

- Comunidade PyTorch
- SciPy/NumPy developers
- Literatura cientÃ­fica de farmacologia

---

**Desenvolvido com â¤ï¸ e ğŸ§  por Luiz Tiago Wilcke**

**Ãšltima atualizaÃ§Ã£o:** 2025-11-25 | **VersÃ£o:** 2.0 (Neural Enhanced)
