import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ConfiguraÃ§Ãµes de estilo
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class SistemaPrevisaoCambialAvancado:
    """
    Sistema sofisticado de previsÃ£o de cÃ¢mbio USD/BRL
    Abordagem hÃ­brida inovadora com mÃºltiplas camadas
    Autor: Luiz Tiago Wilcke
    """
    
    def __init__(self):
        self.dados = None
        self.features_engenharia = None
        self.modelos = {}
        self.metricas = {}
        
    def coletar_dados_abrangentes(self, periodo_anos=10):
        """
        Coleta dados abrangentes de mÃºltiplas fontes
        """
        print("ðŸ”„ Coletando dados abrangentes...")
        
        # Dados principais de cÃ¢mbio
        dados_cambio = yf.download("USDBRL=X", period=f"{periodo_anos}y")
        dados_cambio.columns = ['abertura', 'maximo', 'minimo', 'fechamento', 'volume']
        
        # Dados macroeconÃ´micos brasileiros
        dados_brasil = self._coletar_dados_brasil(dados_cambio.index)
        
        # Dados internacionais
        dados_global = self._coletar_dados_globais(dados_cambio.index)
        
        # Dados de sentimentos e riscos
        dados_sentimento = self._coletar_dados_sentimento(dados_cambio.index)
        
        # Combinar todos os dados
        self.dados = pd.concat([
            dados_cambio, 
            dados_brasil, 
            dados_global,
            dados_sentimento
        ], axis=1)
        
        # Preencher valores missing
        self.dados = self.dados.ffill().bfill()
        
        print(f"âœ… Dados coletados: {self.dados.shape}")
        return self.dados
    
    def _coletar_dados_brasil(self, index_datas):
        """
        Coleta dados macroeconÃ´micos do Brasil (sÃ©ries sintÃ©ticas para demonstraÃ§Ã£o)
        """
        np.random.seed(42)
        n_periodos = len(index_datas)
        
        dados_brasil = pd.DataFrame(index=index_datas)
        
        # Simular sÃ©ries macroeconÃ´micas brasileiras
        dados_brasil['selic'] = np.random.normal(10, 2, n_periodos).cumsum() / 10 + 10
        dados_brasil['ipca'] = np.random.normal(5, 1, n_periodos).cumsum() / 20 + 4
        dados_brasil['pib_brasil'] = np.random.normal(1, 0.5, n_periodos).cumsum() / 10
        dados_brasil['balanca_comercial'] = np.random.normal(0, 2, n_periodos)
        dados_brasil['reservas_internacionais'] = np.random.normal(300, 50, n_periodos).cumsum() / 10 + 300
        dados_brasil['divida_publica'] = np.random.normal(70, 5, n_periodos).cumsum() / 20 + 70
        
        # Adicionar tendÃªncias e sazonalidades realistas
        t = np.arange(n_periodos)
        dados_brasil['selic'] += 0.01 * t  # TendÃªncia de alta
        dados_brasil['ipca'] += 0.005 * np.sin(2 * np.pi * t / 252)  # Sazonalidade anual
        
        return dados_brasil
    
    def _coletar_dados_globais(self, index_datas):
        """
        Coleta dados globais (sÃ©ries sintÃ©ticas para demonstraÃ§Ã£o)
        """
        np.random.seed(43)
        n_periodos = len(index_datas)
        
        dados_global = pd.DataFrame(index=index_datas)
        
        # Dados dos EUA
        dados_global['fed_funds'] = np.random.normal(2, 0.5, n_periodos).cumsum() / 10 + 2
        dados_global['sp500'] = np.random.normal(0.0005, 0.02, n_periodos).cumsum() + 4000
        dados_global['dolar_index'] = np.random.normal(95, 5, n_periodos).cumsum() / 50 + 95
        
        # Commodities
        dados_global['petroleo_brent'] = np.random.normal(70, 10, n_periodos).cumsum() / 20 + 70
        dados_global['commodity_index'] = np.random.normal(100, 15, n_periodos).cumsum() / 30 + 100
        dados_global['iron_ore'] = np.random.normal(100, 20, n_periodos).cumsum() / 25 + 100
        
        # Volatilidade global
        dados_global['vix'] = np.random.normal(15, 5, n_periodos)
        
        return dados_global
    
    def _coletar_dados_sentimento(self, index_datas):
        """
        Coleta dados de sentimento e risco (sÃ©ries sintÃ©ticas)
        """
        np.random.seed(44)
        n_periodos = len(index_datas)
        
        dados_sentimento = pd.DataFrame(index=index_datas)
        
        # Ãndices de risco e sentimento
        dados_sentimento['embi_brasil'] = np.random.normal(200, 50, n_periodos)
        dados_sentimento['sentimento_mercado'] = np.random.normal(0, 1, n_periodos)
        dados_sentimento['fluxo_capital'] = np.random.normal(0, 100, n_periodos)
        dados_sentimento['volatilidade_implÃ­cita'] = np.random.normal(15, 5, n_periodos)
        
        # Eventos de risco (picos aleatÃ³rios)
        eventos_risco = np.zeros(n_periodos)
        eventos_indices = np.random.choice(n_periodos, size=50, replace=False)
        eventos_risco[eventos_indices] = np.random.exponential(2, 50)
        dados_sentimento['eventos_risco'] = eventos_risco
        
        return dados_sentimento
    
    def engenharia_features_sofisticada(self):
        """
        Cria features sofisticadas usando tÃ©cnicas avanÃ§adas
        """
        print("ðŸ”§ Criando features sofisticadas...")
        
        df = self.dados.copy()
        features = pd.DataFrame(index=df.index)
        
        # 1. Features de preÃ§o e retorno
        features['retorno_diario'] = df['fechamento'].pct_change()
        features['retorno_5d'] = df['fechamento'].pct_change(5)
        features['retorno_21d'] = df['fechamento'].pct_change(21)
        features['volatilidade_21d'] = features['retorno_diario'].rolling(21).std()
        features['momentum_63d'] = df['fechamento'] / df['fechamento'].shift(63) - 1
        
        # 2. Features tÃ©cnicas avanÃ§adas
        features['rsi_14'] = self._calcular_rsi(df['fechamento'])
        features['macd'] = self._calcular_macd(df['fechamento'])
        features['bollinger_bands'] = self._calcular_bollinger_bands(df['fechamento'])
        features['atr_14'] = self._calcular_atr(df)
        
        # 3. Features macroeconÃ´micas diferenciais
        features['diferencial_juros'] = df['selic'] - df['fed_funds']
        features['diferencial_inflacao'] = df['ipca'] - 2.0  # vs meta do Fed
        features['termo_troca'] = df['commodity_index'] / df['dolar_index']
        
        # 4. Features de risco relativas
        features['risco_brasil_relativo'] = df['embi_brasil'] / df['vix']
        features['sentimento_ajustado'] = df['sentimento_mercado'] * df['volatilidade_implÃ­cita']
        
        # 5. Features de regime de mercado
        features['regime_alta'] = (features['retorno_21d'] > 0.02).astype(int)
        features['regime_volatil'] = (features['volatilidade_21d'] > features['volatilidade_21d'].quantile(0.7)).astype(int)
        
        # 6. Features de sazonalidade
        features['dia_semana'] = df.index.dayofweek
        features['mes_ano'] = df.index.month
        features['trimestre'] = df.index.quarter
        
        # 7. Features de interaÃ§Ã£o nÃ£o-linear
        features['juros_x_risco'] = features['diferencial_juros'] * features['risco_brasil_relativo']
        features['commodity_x_fluxo'] = df['commodity_index'] * df['fluxo_capital']
        
        # 8. Features de tendÃªncia macro
        for col in ['selic', 'ipca', 'embi_brasil', 'commodity_index']:
            features[f'{col}_tendencia_21d'] = df[col].rolling(21).mean() / df[col].rolling(63).mean() - 1
        
        # Target: Retorno futuro (5 dias)
        features['target_retorno_5d'] = df['fechamento'].shift(-5) / df['fechamento'] - 1
        features['target_direcao_5d'] = (features['target_retorno_5d'] > 0).astype(int)
        
        # Remover valores missing
        features = features.dropna()
        
        self.features_engenharia = features
        print(f"âœ… Features criadas: {features.shape}")
        
        return features
    
    def _calcular_rsi(self, preco, periodo=14):
        """Calcula Relative Strength Index"""
        delta = preco.diff()
        ganho = delta.where(delta > 0, 0).rolling(window=periodo).mean()
        perda = -delta.where(delta < 0, 0).rolling(window=periodo).mean()
        rs = ganho / perda
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def _calcular_macd(self, preco):
        """Calcula MACD"""
        ema_12 = preco.ewm(span=12).mean()
        ema_26 = preco.ewm(span=26).mean()
        macd = ema_12 - ema_26
        return macd
    
    def _calcular_bollinger_bands(self, preco, periodo=20):
        """Calcula posiÃ§Ã£o nas Bandas de Bollinger"""
        media = preco.rolling(periodo).mean()
        std = preco.rolling(periodo).std()
        banda_superior = media + (std * 2)
        banda_inferior = media - (std * 2)
        posicao = (preco - banda_inferior) / (banda_superior - banda_inferior)
        return posicao
    
    def _calcular_atr(self, df, periodo=14):
        """Calcula Average True Range"""
        high_low = df['maximo'] - df['minimo']
        high_close = np.abs(df['maximo'] - df['fechamento'].shift())
        low_close = np.abs(df['minimo'] - df['fechamento'].shift())
        true_range = np.maximum(np.maximum(high_low, high_close), low_close)
        atr = true_range.rolling(periodo).mean()
        return atr
    
    def criar_modelo_hibrido_inovador(self):
        """
        Cria sistema hÃ­brido inovador com mÃºltiplas camadas
        """
        from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
        from sklearn.neural_network import MLPRegressor
        from sklearn.preprocessing import StandardScaler
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        
        print("ðŸ¤– Criando modelo hÃ­brido inovador...")
        
        df = self.features_engenharia.copy()
        
        # Separar features e target
        feature_cols = [col for col in df.columns if col.startswith('target') == False]
        X = df[feature_cols]
        y_retorno = df['target_retorno_5d']
        y_direcao = df['target_direcao_5d']
        
        # DivisÃ£o treino/teste temporal
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train_ret, y_test_ret = y_retorno.iloc[:split_idx], y_retorno.iloc[split_idx:]
        y_train_dir, y_test_dir = y_direcao.iloc[:split_idx], y_direcao.iloc[split_idx:]
        
        # NormalizaÃ§Ã£o
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # 1. Camada 1: Modelo de Ensemble para Retorno
        rf_retorno = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        gb_retorno = GradientBoostingRegressor(n_estimators=100, random_state=42)
        
        rf_retorno.fit(X_train, y_train_ret)
        gb_retorno.fit(X_train, y_train_ret)
        
        # 2. Camada 2: Rede Neural para PadrÃµes Complexos
        mlp_retorno = MLPRegressor(
            hidden_layer_sizes=(100, 50, 25),
            activation='relu',
            solver='adam',
            random_state=42,
            max_iter=1000
        )
        mlp_retorno.fit(X_train_scaled, y_train_ret)
        
        # 3. Camada 3: Modelo de DireÃ§Ã£o
        rf_direcao = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        rf_direcao.fit(X_train, y_train_dir)
        
        # Combinar previsÃµes (Ensemble HÃ­brido)
        pred_rf = rf_retorno.predict(X_test)
        pred_gb = gb_retorno.predict(X_test)
        pred_mlp = mlp_retorno.predict(X_test_scaled)
        
        # Meta-modelo: mÃ©dia ponderada com pesos otimizados
        pesos = np.array([0.4, 0.35, 0.25])  # Pesos baseados em performance histÃ³rica
        pred_retorno_final = pesos[0] * pred_rf + pesos[1] * pred_gb + pesos[2] * pred_mlp
        
        # PrevisÃ£o de direÃ§Ã£o
        pred_direcao = rf_direcao.predict(X_test)
        
        # Armazenar modelos
        self.modelos = {
            'rf_retorno': rf_retorno,
            'gb_retorno': gb_retorno,
            'mlp_retorno': mlp_retorno,
            'rf_direcao': rf_direcao,
            'scaler': scaler,
            'feature_cols': feature_cols
        }
        
        # Calcular mÃ©tricas
        mse = mean_squared_error(y_test_ret, pred_retorno_final)
        mae = mean_absolute_error(y_test_ret, pred_retorno_final)
        r2 = r2_score(y_test_ret, pred_retorno_final)
        acuracia_direcao = np.mean(pred_direcao == y_test_dir)
        
        self.metricas = {
            'mse': mse,
            'mae': mae,
            'r2': r2,
            'acuracia_direcao': acuracia_direcao
        }
        
        print("âœ… Modelo hÃ­brido criado com sucesso!")
        print(f"ðŸ“Š MÃ©tricas - MSE: {mse:.6f}, MAE: {mae:.6f}, RÂ²: {r2:.4f}")
        print(f"ðŸŽ¯ AcurÃ¡cia DireÃ§Ã£o: {acuracia_direcao:.4f}")
        
        return pred_retorno_final, pred_direcao, y_test_ret, y_test_dir
    
    def analisar_importancia_features(self, top_n=15):
        """
        Analisa a importÃ¢ncia das features no modelo
        """
        if 'rf_retorno' not in self.modelos:
            print("âŒ Modelo nÃ£o treinado ainda")
            return
        
        rf_model = self.modelos['rf_retorno']
        feature_cols = self.modelos['feature_cols']
        
        importancias = rf_model.feature_importances_
        indices = np.argsort(importancias)[::-1]
        
        plt.figure(figsize=(12, 8))
        plt.title(f'Top {top_n} Features Mais Importantes - Sistema HÃ­brido')
        plt.barh(range(top_n), importancias[indices[:top_n]][::-1])
        plt.yticks(range(top_n), [feature_cols[i] for i in indices[:top_n]][::-1])
        plt.xlabel('ImportÃ¢ncia Relativa')
        plt.tight_layout()
        plt.show()
        
        return importancias
    
    def visualizar_resultados(self, pred_retorno, y_test_ret, pred_direcao, y_test_dir):
        """
        Visualiza resultados sofisticados do modelo
        """
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Sistema HÃ­brido de PrevisÃ£o Cambial - AnÃ¡lise de Resultados', fontsize=16)
        
        # 1. PrevisÃµes vs Real
        axes[0, 0].plot(y_test_ret.values[:100], label='Real', alpha=0.7)
        axes[0, 0].plot(pred_retorno[:100], label='Previsto', alpha=0.7)
        axes[0, 0].set_title('PrevisÃµes vs Valores Reais (Amostra)')
        axes[0, 0].legend()
        axes[0, 0].set_ylabel('Retorno')
        
        # 2. DistribuiÃ§Ã£o de Erros
        erros = y_test_ret - pred_retorno
        axes[0, 1].hist(erros, bins=50, alpha=0.7, edgecolor='black')
        axes[0, 1].set_title('DistribuiÃ§Ã£o dos Erros de PrevisÃ£o')
        axes[0, 1].set_xlabel('Erro')
        axes[0, 1].set_ylabel('FrequÃªncia')
        
        # 3. Matriz de ConfusÃ£o para DireÃ§Ã£o
        from sklearn.metrics import confusion_matrix
        cm = confusion_matrix(y_test_dir, pred_direcao)
        sns.heatmap(cm, annot=True, fmt='d', ax=axes[1, 0])
        axes[1, 0].set_title('Matriz de ConfusÃ£o - DireÃ§Ã£o')
        axes[1, 0].set_xlabel('Previsto')
        axes[1, 0].set_ylabel('Real')
        
        # 4. AcumulaÃ§Ã£o de Retornos
        retorno_real_acum = (1 + y_test_ret).cumprod()
        retorno_pred_acum = (1 + pred_retorno).cumprod()
        axes[1, 1].plot(retorno_real_acum.values, label='Real')
        axes[1, 1].plot(retorno_pred_acum, label='Previsto')
        axes[1, 1].set_title('Retornos Acumulados')
        axes[1, 1].legend()
        axes[1, 1].set_ylabel('Retorno Acumulado')
        
        plt.tight_layout()
        plt.show()
    
    def gerar_relatorio_executivo(self):
        """
        Gera relatÃ³rio executivo completo do sistema
        """
        print("\n" + "="*80)
        print("ðŸ“Š RELATÃ“RIO EXECUTIVO - SISTEMA HÃBRIDO DE PREVISÃƒO CAMBIAL")
        print("="*80)
        print(f"ðŸ‘¨â€ðŸ’» Autor: Luiz Tiago Wilcke")
        print(f"ðŸ“… Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ðŸ“ˆ PerÃ­odo de Dados: {len(self.dados)} dias")
        print(f"ðŸ”§ Features Criadas: {len(self.modelos.get('feature_cols', []))}")
        print("\nðŸŽ¯ MÃ‰TRICAS DE PERFORMANCE:")
        for metrica, valor in self.metricas.items():
            print(f"   â€¢ {metrica.upper()}: {valor:.6f}")
        
        print("\nðŸš€ CARACTERÃSTICAS INOVADORAS:")
        inovacoes = [
            "Arquitetura hÃ­brida multi-camadas",
            "Engenharia de features macroeconÃ´micas",
            "Modelagem de regimes de mercado", 
            "AnÃ¡lise de sentimentos e riscos",
            "Meta-modelo com ponderaÃ§Ã£o adaptativa",
            "Features de interaÃ§Ã£o nÃ£o-linear"
        ]
        for inovacao in inovacoes:
            print(f"   â€¢ {inovacao}")
        
        print("\nâš ï¸  LIMITAÃ‡Ã•ES E CONSIDERAÃ‡Ã•ES:")
        consideracoes = [
            "Mercado cambial Ã© altamente volÃ¡til",
            "Eventos polÃ­ticos nÃ£o previsÃ­veis",
            "DependÃªncia de dados macroeconÃ´micos atualizados",
            "Necessidade de retreinamento periÃ³dico"
        ]
        for consideracao in consideracoes:
            print(f"   â€¢ {consideracao}")
        
        print("="*80)

# EXECUÃ‡ÃƒO DO SISTEMA
if __name__ == "__main__":
    print("ðŸš€ INICIANDO SISTEMA HÃBRIDO DE PREVISÃƒO CAMBIAL")
    print("ðŸ‘¨â€ðŸ’» Desenvolvido por: Luiz Tiago Wilcke\n")
    
    # Inicializar sistema
    sistema = SistemaPrevisaoCambialAvancado()
    
    # Coletar dados
    dados = sistema.coletar_dados_abrangentes(periodo_anos=8)
    
    # Engenharia de features
    features = sistema.engenharia_features_sofisticada()
    
    # Criar e treinar modelo hÃ­brido
    pred_retorno, pred_direcao, y_test_ret, y_test_dir = sistema.criar_modelo_hibrido_inovador()
    
    # AnÃ¡lise de importÃ¢ncia
    importancias = sistema.analisar_importancia_features()
    
    # VisualizaÃ§Ãµes
    sistema.visualizar_resultados(pred_retorno, y_test_ret, pred_direcao, y_test_dir)
    
    # RelatÃ³rio final
    sistema.gerar_relatorio_executivo()
    
    print("\nâœ… Sistema executado com sucesso!")